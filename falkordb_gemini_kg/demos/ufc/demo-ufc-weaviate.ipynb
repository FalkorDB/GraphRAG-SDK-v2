{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from vertexai.generative_models import GenerativeModel, ChatSession\n",
    "import subprocess\n",
    "import weaviate\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=os.getenv(\"PROJECT_ID\"), location=os.getenv(\"REGION\"))\n",
    "\n",
    "def refresh_token() -> str:\n",
    "    result = subprocess.run(\n",
    "        [\"gcloud\", \"auth\", \"print-access-token\"], capture_output=True, text=True\n",
    "    )\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error refreshing token: {result.stderr}\")\n",
    "        return None\n",
    "    return result.stdout.strip()\n",
    "\n",
    "\n",
    "def re_instantiate_weaviate() -> weaviate.Client:\n",
    "    token = refresh_token()\n",
    "    \n",
    "    client = weaviate.connect_to_local(\n",
    "        headers={\n",
    "            \"X-Google-Vertex-Api-Key\": token,\n",
    "            \"X-Openai-Api-Key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        },\n",
    "    )\n",
    "    return client\n",
    "\n",
    "\n",
    "# Run this every ~60 minutes\n",
    "client = re_instantiate_weaviate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "      client.collections.create(\n",
    "            name=\"ufc\",\n",
    "            vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),    # Set the vectorizer to \"text2vec-openai\" to use the OpenAI API for vector-related operations\n",
    "            generative_config=wvc.config.Configure.Generative.palm(\n",
    "                  project_id=os.getenv(\"PROJECT_ID\"),\n",
    "                  model_id=\"gemini-1.5-pro-preview-0514\"\n",
    "            )\n",
    "      )\n",
    "except Exception as e:\n",
    "      if e.status_code == 422:\n",
    "            print(\"Collection already exists\")\n",
    "      else:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc = client.collections.get(\"ufc\")\n",
    "\n",
    "src_path = \"/Users/davidzimberknopf/Documents/Apps/ufc-crawler/data/event/fight\"\n",
    "sources = []\n",
    "\n",
    "# For each file in the source directory, create a new Source object\n",
    "for file in os.listdir(src_path):\n",
    "    with open(os.path.join(src_path, file), \"r\") as f:\n",
    "        raw = f.read()\n",
    "        soup = BeautifulSoup(raw, \"html.parser\")\n",
    "        title = soup.find(\"title\")\n",
    "        body = soup.find(\"body\")\n",
    "        title_body = (\n",
    "            (title.text if title is not None else \"\")\n",
    "            + (body.text if body is not None else \"\")\n",
    "        ).replace(\"\\n\", \" \")\n",
    "        if title_body != \"\":\n",
    "            ufc.data.insert({\"raw\": title_body[: 8192 * 4]})\n",
    "\n",
    "\n",
    "for i in ufc.iterator():\n",
    "  if i.properties.get(\"raw\") == \"\":\n",
    "    ufc.data.delete_by_id(i.uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc = client.collections.get(\"ufc\")\n",
    "\n",
    "# print(ufc.config.get().properties)\n",
    "\n",
    "for i in ufc.iterator():\n",
    "  if i.properties.get(\"raw\") == \"\":\n",
    "    ufc.data.delete_by_id(i.uuid)\n",
    "\n",
    "# Get size of collection\n",
    "# print(sum(1 for i in ufc.iterator()))\n",
    "\n",
    "# client.collections.delete(\"ufc\")\n",
    "\n",
    "\n",
    "# for i in ufc.iterator():\n",
    "#     print(i.properties.get(\"raw\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerativeModel(\n",
    "    \"gemini-1.5-pro-001\",\n",
    "    system_instruction=\"\"\"\n",
    "You are an assistant that helps to form nice and human understandable answers.\n",
    "The information part contains the provided information that you must use to construct an answer.\n",
    "The provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct or answer it.\n",
    "Make the answer sound as a response to the question. Do not mention that you based the result on the given information.\n",
    "Do not answer more than the question asks for.\n",
    "Here is an example:\n",
    "\n",
    "Question: Which managers own Neo4j stocks?\n",
    "Context:[manager:CTL LLC, manager:JANE STREET GROUP LLC]\n",
    "Helpful Answer: CTL LLC, JANE STREET GROUP LLC owns Neo4j stocks.\n",
    "\n",
    "If the provided information is empty, say that you don't know the answer.\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "generate_prompt = \"\"\"\n",
    "Use the following knowledge to answer the question at the end. \n",
    "\n",
    "History: {history}\n",
    "\n",
    "Context: {raw}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context size:  5\n",
      "Context characters:  13327\n",
      "The last 5 fights were: Michael Morales on November 18, 2023 (3 rounds), Morgan Charriere on April 06, 2024 (3 rounds), Bryan Battle on March 16, 2024 (2 rounds), Bryan Battle on September 23, 2023 (2 rounds), and Morgan Charriere on September 02, 2023 (1 round). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instruction for the generative module\n",
    "question = (\n",
    "    \"What were the last 5 fights? When were they? How many rounds did they have?\"\n",
    ")\n",
    "\n",
    "\n",
    "ufc = client.collections.get(\"ufc\")\n",
    "response = ufc.query.near_text(query=question, limit=5)\n",
    "context = []\n",
    "for r in response.objects:\n",
    "    context.append(r.properties)\n",
    "\n",
    "\n",
    "context_size = len(context)\n",
    "context_chars = sum([len(i[\"raw\"]) for i in context])\n",
    "\n",
    "print(\"Context size: \", str(context_size))\n",
    "print(\"Context characters: \", str(context_chars))\n",
    "\n",
    "answer = model.generate_content(generate_prompt.format(raw=context, question=question, history=[]))\n",
    "\n",
    "print(answer.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context size:  5\n",
      "Context characters:  16685\n",
      "Alexandre Pantoja had 17 takedowns in all fights. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instruction for the generative module\n",
    "question = (\n",
    "    \"How many takedowns did Alexandre Pantoja have in all fights?\"\n",
    ")\n",
    "\n",
    "\n",
    "ufc = client.collections.get(\"ufc\")\n",
    "response = ufc.query.near_text(query=question, limit=5)\n",
    "context = []\n",
    "for r in response.objects:\n",
    "    context.append(r.properties)\n",
    "\n",
    "context_size = len(context)\n",
    "context_chars = sum([len(i[\"raw\"]) for i in context])\n",
    "\n",
    "print(\"Context size: \", str(context_size))\n",
    "print(\"Context characters: \", str(context_chars))\n",
    "\n",
    "answer = model.generate_content(generate_prompt.format(raw=context, question=question, history=[]))\n",
    "\n",
    "print(answer.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context size:  5\n",
      "Context characters:  13848\n",
      "Waldo Cortes-Acosta is nicknamed \"Salsa Boy\". \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instruction for the generative module\n",
    "question1 = \"Who is Salsa Boy?\"\n",
    "\n",
    "\n",
    "ufc = client.collections.get(\"ufc\")\n",
    "response1 = ufc.query.near_text(query=question1, limit=5)\n",
    "\n",
    "context1 = [r.properties.get(\"raw\") for r in response1.objects]\n",
    "\n",
    "answer1 = model.generate_content(\n",
    "    generate_prompt.format(raw=context1, question=question1, history=[])\n",
    ")\n",
    "\n",
    "context_size = len(context1)\n",
    "context_chars = sum([len(i) for i in context1])\n",
    "\n",
    "print(\"Context size: \", str(context_size))\n",
    "print(\"Context characters: \", str(context_chars))\n",
    "\n",
    "print(answer1.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
